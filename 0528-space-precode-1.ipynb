{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dd5ba6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:23.134552Z",
     "iopub.status.busy": "2024-06-13T23:51:23.134100Z",
     "iopub.status.idle": "2024-06-13T23:51:28.228081Z",
     "shell.execute_reply": "2024-06-13T23:51:28.226829Z"
    },
    "papermill": {
     "duration": 5.115333,
     "end_time": "2024-06-13T23:51:28.231060",
     "exception": false,
     "start_time": "2024-06-13T23:51:23.115727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression , LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler, RobustScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, GradientBoostingClassifier, AdaBoostClassifier,StackingClassifier,ExtraTreesClassifier,VotingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.metrics import accuracy_score,log_loss,make_scorer, mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "#赤背景になっている警告を非表示に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08b2b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.263736Z",
     "iopub.status.busy": "2024-06-13T23:51:28.263027Z",
     "iopub.status.idle": "2024-06-13T23:51:28.436233Z",
     "shell.execute_reply": "2024-06-13T23:51:28.434918Z"
    },
    "papermill": {
     "duration": 0.192926,
     "end_time": "2024-06-13T23:51:28.439364",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.246438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/spaceship-titanic/sample_submission.csv\")\n",
    "test_original = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n",
    "train_original = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n",
    "train = train_original\n",
    "test = test_original\n",
    "y_train = train_original[\"Transported\"]\n",
    "\n",
    "data_origin=pd.concat([train,test])\n",
    "data_origin.index = np.arange(0,12970)\n",
    "data = data_origin\n",
    "data[[\"PassengerGroup\",\"PassengerNum\"]] = data[\"PassengerId\"].str.split(\"_\",expand=True)\n",
    "\n",
    "def split_column(value):\n",
    "    if isinstance(value, str) and'/' in value:\n",
    "        #isinstanceとは（）の最初のオブジェクト型と、2番目のオブジェクト型が一致しているか確認。今回はvalueがstrings型になっているかを確認\n",
    "        return value.split('/')\n",
    "    else:\n",
    "        return [None, None,None]\n",
    "\n",
    "# 列を分割して新しい列を作成\n",
    "split_data = data[\"Cabin\"].apply(split_column)\n",
    "#dataframe.apply（関数）でdataframeに対して「関数」を繰り返し記録できる\n",
    "data[[\"Cabin_1\",\"Cabin_2\",\"Cabin_3\"]] = pd.DataFrame(split_data.tolist(), index=data.index)\n",
    "data[\"Cabin_2\"] = data[\"Cabin_2\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20597a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.472601Z",
     "iopub.status.busy": "2024-06-13T23:51:28.472118Z",
     "iopub.status.idle": "2024-06-13T23:51:28.523076Z",
     "shell.execute_reply": "2024-06-13T23:51:28.521799Z"
    },
    "papermill": {
     "duration": 0.070764,
     "end_time": "2024-06-13T23:51:28.525970",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.455206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_total</th>\n",
       "      <th>Percent (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <td>4277</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>310</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>306</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>299</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_1</th>\n",
       "      <td>299</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_2</th>\n",
       "      <td>299</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_3</th>\n",
       "      <td>299</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>296</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>294</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>289</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>288</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>284</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>274</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>270</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>268</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>263</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing_total  Percent (%)\n",
       "Transported            4277         33.0\n",
       "CryoSleep               310          2.4\n",
       "ShoppingMall            306          2.4\n",
       "Cabin                   299          2.3\n",
       "Cabin_1                 299          2.3\n",
       "Cabin_2                 299          2.3\n",
       "Cabin_3                 299          2.3\n",
       "VIP                     296          2.3\n",
       "Name                    294          2.3\n",
       "FoodCourt               289          2.2\n",
       "HomePlanet              288          2.2\n",
       "Spa                     284          2.2\n",
       "Destination             274          2.1\n",
       "Age                     270          2.1\n",
       "VRDeck                  268          2.1\n",
       "RoomService             263          2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 欠損値の数を計算\n",
    "missing_values_count = data.isnull().sum()\n",
    "\n",
    "# 欠損値の数とパーセンテージを表形式で表示するためのDataFrameを作成\n",
    "missing_values_table = pd.DataFrame({\n",
    "    'Missing_total': missing_values_count,\n",
    "    'Percent (%)': round((missing_values_count / len(data)) * 100, 1)\n",
    "})\n",
    "\n",
    "# 欠損値がある列の情報を抽出して降順でソート\n",
    "df_missing = missing_values_table[missing_values_table['Missing_total'] > 0].sort_values(by='Missing_total', ascending=False)\n",
    "    \n",
    "# 欠損値がある列の情報を表示\n",
    "display(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c1327e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.561461Z",
     "iopub.status.busy": "2024-06-13T23:51:28.560992Z",
     "iopub.status.idle": "2024-06-13T23:51:28.569104Z",
     "shell.execute_reply": "2024-06-13T23:51:28.567777Z"
    },
    "papermill": {
     "duration": 0.027749,
     "end_time": "2024-06-13T23:51:28.571897",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.544148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#VIPかそうでないかを分けて、欠損値処理を実施\\nlist_0 = [\"ShoppingMall\",\"FoodCourt\",\"Spa\",\"VRDeck\",\"RoomService\"]\\n\\nfor vip_col in list_0:\\n    data[vip_col] = data[vip_col].mask(data[vip_col].isnull() & data[\"VIP\"]==True,data.loc[data[\"VIP\"]==True][vip_col].mean())\\n\\ndata[list_0] = data[list_0].fillna(0)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#VIPかそうでないかを分けて、欠損値処理を実施\n",
    "list_0 = [\"ShoppingMall\",\"FoodCourt\",\"Spa\",\"VRDeck\",\"RoomService\"]\n",
    "\n",
    "for vip_col in list_0:\n",
    "    data[vip_col] = data[vip_col].mask(data[vip_col].isnull() & data[\"VIP\"]==True,data.loc[data[\"VIP\"]==True][vip_col].mean())\n",
    "\n",
    "data[list_0] = data[list_0].fillna(0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f75fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.604981Z",
     "iopub.status.busy": "2024-06-13T23:51:28.604497Z",
     "iopub.status.idle": "2024-06-13T23:51:28.669178Z",
     "shell.execute_reply": "2024-06-13T23:51:28.667548Z"
    },
    "papermill": {
     "duration": 0.084874,
     "end_time": "2024-06-13T23:51:28.672283",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.587409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_0 = [\"ShoppingMall\",\"FoodCourt\",\"Spa\",\"VRDeck\",\"RoomService\",\"Cabin_2\"]\n",
    "for col in list_0 :\n",
    "    data[list_0] = data[list_0].fillna(0)\n",
    "\n",
    "list_median = [\"Age\"]\n",
    "data[list_median] = data[list_median].fillna(data[list_median].median())\n",
    "\n",
    "list_None = [\"Cabin_3\",\"Cabin\",\"Name\"]\n",
    "data[list_None] = data[list_None].fillna(\"None\")\n",
    "data[\"Cabin_1\"] = data[\"Cabin_1\"].fillna(0)\n",
    "\n",
    "#list_node=[\"Destination\",\"HomePlanet\",\"VIP\",\"CryoSleep\"]\n",
    "list_node=[\"Destination\",\"HomePlanet\"]\n",
    "for col in list_node:\n",
    "    mode_value = data[col].mode()[0]\n",
    "    data[col] = data[col].fillna(mode_value)\n",
    "#最頻値はdata.mode()をリスト形式で返すため、fillna(data.mode())では表示ができない。そのためfor文で入力している\n",
    "\n",
    "list_None2 = [\"VIP\",\"CryoSleep\"]\n",
    "for col in list_None2:\n",
    "    data[col] = data[col].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d141b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.706352Z",
     "iopub.status.busy": "2024-06-13T23:51:28.705897Z",
     "iopub.status.idle": "2024-06-13T23:51:28.735218Z",
     "shell.execute_reply": "2024-06-13T23:51:28.733794Z"
    },
    "papermill": {
     "duration": 0.049639,
     "end_time": "2024-06-13T23:51:28.738150",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.688511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def torf(value):\n",
    "    if value is False:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "torf_list = [\"CryoSleep\",\"VIP\"]\n",
    "\n",
    "for col in  torf_list:\n",
    "    data[col] = data[col].apply(torf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7ca67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.771754Z",
     "iopub.status.busy": "2024-06-13T23:51:28.771241Z",
     "iopub.status.idle": "2024-06-13T23:51:28.779515Z",
     "shell.execute_reply": "2024-06-13T23:51:28.778205Z"
    },
    "papermill": {
     "duration": 0.028496,
     "end_time": "2024-06-13T23:51:28.782457",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.753961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef overor0(value):\\n    if value!=0:\\n        return 1\\n    else:\\n        return 0\\n\\nover0_list = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]    \\nfor col in over0_list:\\n    data[col] = data[col].apply(overor0)\\n    \\ndef cabin2(value):\\n    if value == \"None\":\\n        return \"None\"\\n    elif 0<=value<=300 or 750<value<=1150:\\n        return \"0\"\\n    else:\\n        return \"1\"\\n    \\ndata[\"Cabin_2\"] = data[\"Cabin_2\"].apply(cabin2)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def overor0(value):\n",
    "    if value!=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "over0_list = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]    \n",
    "for col in over0_list:\n",
    "    data[col] = data[col].apply(overor0)\n",
    "    \n",
    "def cabin2(value):\n",
    "    if value == \"None\":\n",
    "        return \"None\"\n",
    "    elif 0<=value<=300 or 750<value<=1150:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "    \n",
    "data[\"Cabin_2\"] = data[\"Cabin_2\"].apply(cabin2)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2abf3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.817024Z",
     "iopub.status.busy": "2024-06-13T23:51:28.815690Z",
     "iopub.status.idle": "2024-06-13T23:51:28.829930Z",
     "shell.execute_reply": "2024-06-13T23:51:28.828611Z"
    },
    "papermill": {
     "duration": 0.03451,
     "end_time": "2024-06-13T23:51:28.832781",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.798271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_idx = [8415,4416,5105,5722,7995,4311,5619]\n",
    "#drop_idx=[725,3366,4311,5619,6547,1095,1390,1598,4278,5722,6921,7995,4724,6223,7425,8415,1213,1842,2067,3198,3538,928,1177,4416,4762,5105,5725,7118,7933,8626]\n",
    "data = data.drop(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81bcf8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:28.866261Z",
     "iopub.status.busy": "2024-06-13T23:51:28.865811Z",
     "iopub.status.idle": "2024-06-13T23:51:28.993053Z",
     "shell.execute_reply": "2024-06-13T23:51:28.991927Z"
    },
    "papermill": {
     "duration": 0.147502,
     "end_time": "2024-06-13T23:51:28.995992",
     "exception": false,
     "start_time": "2024-06-13T23:51:28.848490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "passengernum = data.groupby(\"PassengerGroup\").count()[\"PassengerNum\"]\n",
    "data = pd.merge(data,passengernum,on=\"PassengerGroup\",how=\"left\")\n",
    "\n",
    "data[\"pay_sum\"] = data['RoomService']+data['FoodCourt']+data['ShoppingMall']+data['Spa']+data['VRDeck']\n",
    "\n",
    "#data[\"Cabin_13\"] = data[\"Cabin_1\"].astype(str)+data[\"Cabin_3\"]\n",
    "data[\"Cabin_1\"] = data[\"Cabin_1\"].replace([\"T\",\"E\",\"D\",\"F\",\"G\",\"A\",\"C\",\"B\"],np.arange(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f449be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.029067Z",
     "iopub.status.busy": "2024-06-13T23:51:29.028613Z",
     "iopub.status.idle": "2024-06-13T23:51:29.035985Z",
     "shell.execute_reply": "2024-06-13T23:51:29.034805Z"
    },
    "papermill": {
     "duration": 0.026908,
     "end_time": "2024-06-13T23:51:29.038490",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.011582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#グループの一人当たりの平均支払額を特徴量として追加\\ngroup_pay = data.groupby(\"PassengerGroup\").sum()[\"pay_sum\"]\\ndata = pd.merge(data,group_pay,on=\"PassengerGroup\",how=\"left\")\\ndata[\"pay_sum_y\"] = data[\"pay_sum_y\"]/data[\"PassengerNum_y\"]\\ndata = data.rename(columns={\"pay_sum_x\":\"pay_sum\",\"pay_sum_y\":\"pay_per_passenger\"})\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#グループの一人当たりの平均支払額を特徴量として追加\n",
    "group_pay = data.groupby(\"PassengerGroup\").sum()[\"pay_sum\"]\n",
    "data = pd.merge(data,group_pay,on=\"PassengerGroup\",how=\"left\")\n",
    "data[\"pay_sum_y\"] = data[\"pay_sum_y\"]/data[\"PassengerNum_y\"]\n",
    "data = data.rename(columns={\"pay_sum_x\":\"pay_sum\",\"pay_sum_y\":\"pay_per_passenger\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beb41e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.072555Z",
     "iopub.status.busy": "2024-06-13T23:51:29.072169Z",
     "iopub.status.idle": "2024-06-13T23:51:29.080177Z",
     "shell.execute_reply": "2024-06-13T23:51:29.079023Z"
    },
    "papermill": {
     "duration": 0.027854,
     "end_time": "2024-06-13T23:51:29.082538",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.054684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nname_list = data[\"Name\"].str.split(\" \").tolist()\\ndata[\"Name_first\"] = pd.DataFrame(list(map(lambda x:x[0],name_list)))\\ndata[\"Name_last\"] = pd.DataFrame(list(map(lambda x:x[1],name_list)))\\n#map(lambda x:xの処理 , list)で、listをxの処理へ繰り返すという関数になる。map はdefの代わり。mapはfor文の代わりになる\\n\\nnamelastnum = data.groupby([\"Name_last\",\"Cabin\"]).count()[\"Name_first\"]\\ndata = pd.merge(data,namelastnum,on=[\"Name_last\",\"Cabin\"],how=\"left\")\\ndata = data.rename(columns={\"Name_first_y\":\"Name_last_count\"})\\ndata\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "name_list = data[\"Name\"].str.split(\" \").tolist()\n",
    "data[\"Name_first\"] = pd.DataFrame(list(map(lambda x:x[0],name_list)))\n",
    "data[\"Name_last\"] = pd.DataFrame(list(map(lambda x:x[1],name_list)))\n",
    "#map(lambda x:xの処理 , list)で、listをxの処理へ繰り返すという関数になる。map はdefの代わり。mapはfor文の代わりになる\n",
    "\n",
    "namelastnum = data.groupby([\"Name_last\",\"Cabin\"]).count()[\"Name_first\"]\n",
    "data = pd.merge(data,namelastnum,on=[\"Name_last\",\"Cabin\"],how=\"left\")\n",
    "data = data.rename(columns={\"Name_first_y\":\"Name_last_count\"})\n",
    "data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5225e35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.116955Z",
     "iopub.status.busy": "2024-06-13T23:51:29.116484Z",
     "iopub.status.idle": "2024-06-13T23:51:29.125805Z",
     "shell.execute_reply": "2024-06-13T23:51:29.124612Z"
    },
    "papermill": {
     "duration": 0.029378,
     "end_time": "2024-06-13T23:51:29.128267",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.098889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#歪度の削減の手法を用いていきます。そのため、まずは現状の歪度が高いもの (0.75以上) を抽出します。\\nfrom scipy.stats import skew\\n# 数値変数を特定\\nnumeric_feats = data.dtypes[data.dtypes != \"object\"].index\\n# 各数値変数の歪度を計算し、降順にソート\\nskewed_feats = data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\\n# 歪度を含むデータフレームの作成\\nskewness = pd.DataFrame({\\'Skew\\' :skewed_feats})\\n# 歪度の絶対値が0.75より大きい特徴量を選択\\nskewness = skewness[abs(skewness) > 0.75]\\n# 歪度が0.75より小さい特徴量を削除\\nskewness = skewness.dropna(axis=0)\\n\\n\\n#歪度の絶対値が0.75以上のものに対してBox-Cox変換を適用していきます\\nfrom scipy.special import boxcox1p\\n# Box-Cox変換を適用する数値変数の列を特定\\nindices = skewness.index\\n# 新しい列を格納するための空のリストを作成\\nskewness_after_boxcox = []\\n# Box-Cox変換のパラメータ（ラムダ）を設定\\nlam = 0.15\\n# 各数値変数に対してBox-Cox変換を適用し、新しい列として追加\\nfor idx in indices:\\n    transformed_values = boxcox1p(data[idx], lam)\\n    data[idx] = transformed_values\\n    # Box-Cox変換後の歪度を計算し、リストに追加\\n    skewness_after_boxcox.append(skew(transformed_values))\\n# skewnessデータフレームにBox-Cox変換後の歪度を追加\\nskewness[\\'Skew_BoxCox\\'] = skewness_after_boxcox\\n# Box-Cox変換後の歪度を表示\\ndisplay(skewness.head(10))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#歪度の削減の手法を用いていきます。そのため、まずは現状の歪度が高いもの (0.75以上) を抽出します。\n",
    "from scipy.stats import skew\n",
    "# 数値変数を特定\n",
    "numeric_feats = data.dtypes[data.dtypes != \"object\"].index\n",
    "# 各数値変数の歪度を計算し、降順にソート\n",
    "skewed_feats = data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "# 歪度を含むデータフレームの作成\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "# 歪度の絶対値が0.75より大きい特徴量を選択\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "# 歪度が0.75より小さい特徴量を削除\n",
    "skewness = skewness.dropna(axis=0)\n",
    "\n",
    "\n",
    "#歪度の絶対値が0.75以上のものに対してBox-Cox変換を適用していきます\n",
    "from scipy.special import boxcox1p\n",
    "# Box-Cox変換を適用する数値変数の列を特定\n",
    "indices = skewness.index\n",
    "# 新しい列を格納するための空のリストを作成\n",
    "skewness_after_boxcox = []\n",
    "# Box-Cox変換のパラメータ（ラムダ）を設定\n",
    "lam = 0.15\n",
    "# 各数値変数に対してBox-Cox変換を適用し、新しい列として追加\n",
    "for idx in indices:\n",
    "    transformed_values = boxcox1p(data[idx], lam)\n",
    "    data[idx] = transformed_values\n",
    "    # Box-Cox変換後の歪度を計算し、リストに追加\n",
    "    skewness_after_boxcox.append(skew(transformed_values))\n",
    "# skewnessデータフレームにBox-Cox変換後の歪度を追加\n",
    "skewness['Skew_BoxCox'] = skewness_after_boxcox\n",
    "# Box-Cox変換後の歪度を表示\n",
    "display(skewness.head(10))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274870e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.163803Z",
     "iopub.status.busy": "2024-06-13T23:51:29.163378Z",
     "iopub.status.idle": "2024-06-13T23:51:29.171284Z",
     "shell.execute_reply": "2024-06-13T23:51:29.170076Z"
    },
    "papermill": {
     "duration": 0.028912,
     "end_time": "2024-06-13T23:51:29.173831",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.144919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata[\"HomePlanet\"] = data[\"HomePlanet\"].replace([\"Europa\",\"Earth\",\"Mars\"],[3,1,2])\\ndata[\"Destination\"] = data[\"Destination\"].replace([\"TRAPPIST-1e\",\"55 Cancri e\",\"PSO J318.5-22\"],[1,3,2])\\n\\nle = LabelEncoder()\\ndata[\"Cabin_3\"] = le.fit_transform(data[\"Cabin_3\"])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data[\"HomePlanet\"] = data[\"HomePlanet\"].replace([\"Europa\",\"Earth\",\"Mars\"],[3,1,2])\n",
    "data[\"Destination\"] = data[\"Destination\"].replace([\"TRAPPIST-1e\",\"55 Cancri e\",\"PSO J318.5-22\"],[1,3,2])\n",
    "\n",
    "le = LabelEncoder()\n",
    "data[\"Cabin_3\"] = le.fit_transform(data[\"Cabin_3\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b203e8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.207991Z",
     "iopub.status.busy": "2024-06-13T23:51:29.207579Z",
     "iopub.status.idle": "2024-06-13T23:51:29.215950Z",
     "shell.execute_reply": "2024-06-13T23:51:29.214701Z"
    },
    "papermill": {
     "duration": 0.028651,
     "end_time": "2024-06-13T23:51:29.218736",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.190085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data\n",
    "drop_list=[\"PassengerId\",\"Cabin\",\"Name\",\"PassengerNum_x\",\"PassengerGroup\"]\n",
    "train_data = train_data.drop(drop_list,axis=1)\n",
    "\n",
    "#drop_list_a=[\"Cabin_1\",\"Cabin_3\"]\n",
    "#train_data = train_data.drop(drop_list_a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5086182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.254000Z",
     "iopub.status.busy": "2024-06-13T23:51:29.252903Z",
     "iopub.status.idle": "2024-06-13T23:51:29.284317Z",
     "shell.execute_reply": "2024-06-13T23:51:29.283237Z"
    },
    "papermill": {
     "duration": 0.0524,
     "end_time": "2024-06-13T23:51:29.287385",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.234985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_trans=train_data[\"Transported\"]\n",
    "data_trans = data_trans.replace([True,False],[1,0])\n",
    "\n",
    "data_obj = train_data.select_dtypes(include=object)\n",
    "data_obj = data_obj.drop(\"Transported\",axis=1)\n",
    "data_obj_dummy = pd.get_dummies(data_obj,dtype=int)\n",
    "\n",
    "data_category = train_data[['CryoSleep','VIP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3b85d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.323668Z",
     "iopub.status.busy": "2024-06-13T23:51:29.323247Z",
     "iopub.status.idle": "2024-06-13T23:51:29.330910Z",
     "shell.execute_reply": "2024-06-13T23:51:29.329698Z"
    },
    "papermill": {
     "duration": 0.029457,
     "end_time": "2024-06-13T23:51:29.333752",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.304295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_trans=train_data[\"Transported\"]\\ndata_trans = data_trans.replace([True,False],[1,0])\\n\\ndata_category = train_data[[\\'CryoSleep\\',\\'VIP\\']]\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_trans=train_data[\"Transported\"]\n",
    "data_trans = data_trans.replace([True,False],[1,0])\n",
    "\n",
    "data_category = train_data[['CryoSleep','VIP']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100fc5be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.369930Z",
     "iopub.status.busy": "2024-06-13T23:51:29.369511Z",
     "iopub.status.idle": "2024-06-13T23:51:29.377774Z",
     "shell.execute_reply": "2024-06-13T23:51:29.376350Z"
    },
    "papermill": {
     "duration": 0.029861,
     "end_time": "2024-06-13T23:51:29.380517",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.350656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_number_sc = train_data[[\"Age\",\"PassengerNum_y\",\\'RoomService\\', \\'FoodCourt\\', \\'ShoppingMall\\',\\'Spa\\', \\'VRDeck\\',\"Cabin_1\",\"Cabin_2\",\"pay_sum\"]]\\ncolumns = data_number.columns\\n\\nsc = StandardScaler()\\nsc.fit(data_number)\\ndata_std = sc.transform(data_number)\\ndata_std = pd.DataFrame(data_std,columns=columns)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_number_sc = train_data[[\"Age\",\"PassengerNum_y\",'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck',\"Cabin_1\",\"Cabin_2\",\"pay_sum\"]]\n",
    "columns = data_number.columns\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(data_number)\n",
    "data_std = sc.transform(data_number)\n",
    "data_std = pd.DataFrame(data_std,columns=columns)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6eca408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.416015Z",
     "iopub.status.busy": "2024-06-13T23:51:29.415568Z",
     "iopub.status.idle": "2024-06-13T23:51:29.437332Z",
     "shell.execute_reply": "2024-06-13T23:51:29.436167Z"
    },
    "papermill": {
     "duration": 0.043174,
     "end_time": "2024-06-13T23:51:29.440317",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.397143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_number = train_data[[\"Age\",\"PassengerNum_y\",'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck',\"Cabin_1\",\"Cabin_2\",\"pay_sum\",]]\n",
    "#data_number = train_data[[\"Age\",\"PassengerNum_y\",'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck',\"Cabin_1\",\"Cabin_2\",\"pay_sum\",\"HomePlanet\",\"Destination\",\"Cabin_3\"]]\n",
    "columns = data_number.columns\n",
    "\n",
    "rs = RobustScaler()\n",
    "#中央値を中心にスケーリングし、四分位範囲（IQR）を基準にスケーリングします。\n",
    "#メリット:外れ値に対して頑健です。外れ値の影響を受けにくいため、外れ値が存在するデータセットで効果的です。\n",
    "rs.fit(data_number)\n",
    "data_std = rs.transform(data_number)\n",
    "data_std = pd.DataFrame(data_std,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "318b56e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.475746Z",
     "iopub.status.busy": "2024-06-13T23:51:29.475331Z",
     "iopub.status.idle": "2024-06-13T23:51:29.520204Z",
     "shell.execute_reply": "2024-06-13T23:51:29.518871Z"
    },
    "papermill": {
     "duration": 0.065744,
     "end_time": "2024-06-13T23:51:29.523028",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.457284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>Cabin_3_None</th>\n",
       "      <th>Cabin_3_P</th>\n",
       "      <th>Cabin_3_S</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_1</th>\n",
       "      <th>Cabin_2</th>\n",
       "      <th>pay_sum</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>VIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>-0.496533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>11.090909</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>58.146341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.656566</td>\n",
       "      <td>1.361111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>6.703883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>...</td>\n",
       "      <td>20.861789</td>\n",
       "      <td>16.130435</td>\n",
       "      <td>67.252525</td>\n",
       "      <td>5.361111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>3.092926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.647059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.138211</td>\n",
       "      <td>6.565217</td>\n",
       "      <td>11.414141</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488942</td>\n",
       "      <td>0.260055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.298267</td>\n",
       "      <td>-0.496533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>13.772358</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>0.209431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.136282</td>\n",
       "      <td>-0.496533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12961</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.577236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.527778</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.135087</td>\n",
       "      <td>1.724688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12962</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.300658</td>\n",
       "      <td>-0.496533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12963 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  \\\n",
       "0                     0                  1                0   \n",
       "1                     1                  0                0   \n",
       "2                     0                  1                0   \n",
       "3                     0                  1                0   \n",
       "4                     1                  0                0   \n",
       "...                 ...                ...              ...   \n",
       "12958                 1                  0                0   \n",
       "12959                 1                  0                0   \n",
       "12960                 0                  0                1   \n",
       "12961                 0                  1                0   \n",
       "12962                 1                  0                0   \n",
       "\n",
       "       Destination_55 Cancri e  Destination_PSO J318.5-22  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "12958                        0                          0   \n",
       "12959                        0                          0   \n",
       "12960                        1                          0   \n",
       "12961                        0                          0   \n",
       "12962                        0                          1   \n",
       "\n",
       "       Destination_TRAPPIST-1e  Cabin_3_None  Cabin_3_P  Cabin_3_S       Age  \\\n",
       "0                            1             0          1          0  0.705882   \n",
       "1                            1             0          0          1 -0.176471   \n",
       "2                            1             0          0          1  1.823529   \n",
       "3                            1             0          0          1  0.352941   \n",
       "4                            1             0          0          1 -0.647059   \n",
       "...                        ...           ...        ...        ...       ...   \n",
       "12958                        1             0          0          1  0.411765   \n",
       "12959                        1             1          0          0  0.882353   \n",
       "12960                        0             0          1          0  0.000000   \n",
       "12961                        1             0          1          0  0.000000   \n",
       "12962                        0             0          0          1  0.941176   \n",
       "\n",
       "       ...  FoodCourt  ShoppingMall         Spa     VRDeck  Cabin_1   Cabin_2  \\\n",
       "0      ...   0.000000      0.000000    0.000000   0.000000      4.0 -0.490137   \n",
       "1      ...   0.146341      1.086957   11.090909   1.222222      0.0 -0.490137   \n",
       "2      ...  58.146341      0.000000  135.656566   1.361111      2.0 -0.490137   \n",
       "3      ...  20.861789     16.130435   67.252525   5.361111      2.0 -0.490137   \n",
       "4      ...   1.138211      6.565217   11.414141   0.055556      0.0 -0.488942   \n",
       "...    ...        ...           ...         ...        ...      ...       ...   \n",
       "12958  ...   0.000000      0.000000    0.000000   0.000000      1.0  1.298267   \n",
       "12959  ...  13.772358      0.739130    0.202020   4.000000     -4.0 -0.490137   \n",
       "12960  ...   0.000000      0.000000    0.000000   0.000000     -1.0 -0.136282   \n",
       "12961  ...  43.577236      0.000000    0.000000  14.527778     -1.0 -0.135087   \n",
       "12962  ...   0.000000      0.000000    0.000000   0.000000      1.0  1.300658   \n",
       "\n",
       "        pay_sum  Transported  CryoSleep  VIP  \n",
       "0     -0.496533          0.0          0    0  \n",
       "1      0.013870          1.0          0    0  \n",
       "2      6.703883          0.0          0    1  \n",
       "3      3.092926          0.0          0    0  \n",
       "4      0.260055          1.0          0    0  \n",
       "...         ...          ...        ...  ...  \n",
       "12958 -0.496533          NaN          1    0  \n",
       "12959  0.209431          NaN          0    0  \n",
       "12960 -0.496533          NaN          1    0  \n",
       "12961  1.724688          NaN          0    0  \n",
       "12962 -0.496533          NaN          1    0  \n",
       "\n",
       "[12963 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_obj_dummy.join(data_std)\n",
    "data_train = data_train.join(data_trans)\n",
    "#data_train = data_std.join(data_trans)\n",
    "data_train = data_train.join(data_category)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6950542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.559405Z",
     "iopub.status.busy": "2024-06-13T23:51:29.559015Z",
     "iopub.status.idle": "2024-06-13T23:51:29.566372Z",
     "shell.execute_reply": "2024-06-13T23:51:29.565197Z"
    },
    "papermill": {
     "duration": 0.02876,
     "end_time": "2024-06-13T23:51:29.569070",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.540310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndrop_list=[\\'ShoppingMall\\',\"Age\",\\'HomePlanet_Earth\\',\\'FoodCourt\\',\\'Destination_TRAPPIST-1e\\', \"Cabin_3_P\"]\\ndata_train = data_train.drop(drop_list,axis=1)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "drop_list=['ShoppingMall',\"Age\",'HomePlanet_Earth','FoodCourt','Destination_TRAPPIST-1e', \"Cabin_3_P\"]\n",
    "data_train = data_train.drop(drop_list,axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b40ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.605931Z",
     "iopub.status.busy": "2024-06-13T23:51:29.605513Z",
     "iopub.status.idle": "2024-06-13T23:51:29.615934Z",
     "shell.execute_reply": "2024-06-13T23:51:29.614771Z"
    },
    "papermill": {
     "duration": 0.032258,
     "end_time": "2024-06-13T23:51:29.618734",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.586476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = data_train.loc[data_train[\"Transported\"].notna()]\n",
    "df_test = data_train.loc[data_train[\"Transported\"].isna()]\n",
    "df_test = df_test.drop(\"Transported\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb70a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.655978Z",
     "iopub.status.busy": "2024-06-13T23:51:29.655549Z",
     "iopub.status.idle": "2024-06-13T23:51:29.663906Z",
     "shell.execute_reply": "2024-06-13T23:51:29.662572Z"
    },
    "papermill": {
     "duration": 0.029932,
     "end_time": "2024-06-13T23:51:29.666378",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.636446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SequentialFeatureSelector\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nmodel_lgbm = LGBMClassifier(verbose=-1)\\nsf = SequentialFeatureSelector(model_lgbm, scoring=\\'accuracy\\', direction = \\'backward\\')\\nsf.fit(X,y)\\n\\n# 選ばれた特徴量のブールマスクを取得\\nselected_mask = sf.get_support()\\n\\n# 選ばれたカラム名を取得\\nselected_columns = X.columns[selected_mask]\\n\\n# 選ばれたカラム名を出力\\nprint(f\\'Selected columns: {selected_columns}\\')\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "model_lgbm = LGBMClassifier(verbose=-1)\n",
    "sf = SequentialFeatureSelector(model_lgbm, scoring='accuracy', direction = 'backward')\n",
    "sf.fit(X,y)\n",
    "\n",
    "# 選ばれた特徴量のブールマスクを取得\n",
    "selected_mask = sf.get_support()\n",
    "\n",
    "# 選ばれたカラム名を取得\n",
    "selected_columns = X.columns[selected_mask]\n",
    "\n",
    "# 選ばれたカラム名を出力\n",
    "print(f'Selected columns: {selected_columns}')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3300a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.703437Z",
     "iopub.status.busy": "2024-06-13T23:51:29.703041Z",
     "iopub.status.idle": "2024-06-13T23:51:29.708828Z",
     "shell.execute_reply": "2024-06-13T23:51:29.707441Z"
    },
    "papermill": {
     "duration": 0.02732,
     "end_time": "2024-06-13T23:51:29.711337",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.684017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns = ['HomePlanet_Europa', 'Destination_TRAPPIST-1e', 'Cabin_3_P',\n",
    "       'PassengerNum_y', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "       'Cabin_1', 'pay_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf166401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.749025Z",
     "iopub.status.busy": "2024-06-13T23:51:29.748147Z",
     "iopub.status.idle": "2024-06-13T23:51:29.755772Z",
     "shell.execute_reply": "2024-06-13T23:51:29.754628Z"
    },
    "papermill": {
     "duration": 0.029359,
     "end_time": "2024-06-13T23:51:29.758387",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.729028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#isolation forestによる異常値検知\\n#Random Forestと同様に決定木に基づいて構築されます。決定木を各データが孤立するまで分割を繰り返し、データが孤立するまでの距離（深さ）から異常値を推定しよう、というのが基本的なアイディアです\\n\\n\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Isolation Forestによる外れ値検出\\niso = IsolationForest(contamination=0.01)\\nyhat = iso.fit_predict(df_train)\\n\\n# 外れ値を除外\\nmask = yhat != -1\\ndf_train = df_train[mask]\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#isolation forestによる異常値検知\n",
    "#Random Forestと同様に決定木に基づいて構築されます。決定木を各データが孤立するまで分割を繰り返し、データが孤立するまでの距離（深さ）から異常値を推定しよう、というのが基本的なアイディアです\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Isolation Forestによる外れ値検出\n",
    "iso = IsolationForest(contamination=0.01)\n",
    "yhat = iso.fit_predict(df_train)\n",
    "\n",
    "# 外れ値を除外\n",
    "mask = yhat != -1\n",
    "df_train = df_train[mask]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ffa618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.859888Z",
     "iopub.status.busy": "2024-06-13T23:51:29.858828Z",
     "iopub.status.idle": "2024-06-13T23:51:29.868669Z",
     "shell.execute_reply": "2024-06-13T23:51:29.867073Z"
    },
    "papermill": {
     "duration": 0.031798,
     "end_time": "2024-06-13T23:51:29.871345",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.839547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# ベースモデルの定義\\nbase_models = [\\n    (\\'knn\\', KNeighborsClassifier()),\\n    (\\'lr\\', LogisticRegression(max_iter=1000)),\\n    (\\'svc\\', SVC(probability=True)),\\n    (\\'rf\\', RandomForestClassifier()),\\n    (\\'xgb\\', XGBClassifier()),\\n    (\\'lgbm\\', LGBMClassifier(verbose=-1))\\n]\\n\\n# メタモデルの定義\\nmeta_model = LogisticRegression()\\n\\n# Stacking Classifierの定義\\nstacking = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\\n# Stacking Classifierの学習\\nstacking.fit(X_train, y_train)\\n# 予測\\ny_pred = stacking.predict(X_test)\\n# 精度の評価\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\'Stacking Model Accuracy: {accuracy:.4f}\\')\\n\\n\\nsubmit = stacking.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ベースモデルの定義\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('lgbm', LGBMClassifier(verbose=-1))\n",
    "]\n",
    "\n",
    "# メタモデルの定義\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking Classifierの定義\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "# Stacking Classifierの学習\n",
    "stacking.fit(X_train, y_train)\n",
    "# 予測\n",
    "y_pred = stacking.predict(X_test)\n",
    "# 精度の評価\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Stacking Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "submit = stacking.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ee962",
   "metadata": {
    "papermill": {
     "duration": 0.017443,
     "end_time": "2024-06-13T23:51:29.907246",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.889803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* LogisticRegression：0.8119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b24781e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.947130Z",
     "iopub.status.busy": "2024-06-13T23:51:29.946047Z",
     "iopub.status.idle": "2024-06-13T23:51:29.954023Z",
     "shell.execute_reply": "2024-06-13T23:51:29.952879Z"
    },
    "papermill": {
     "duration": 0.031203,
     "end_time": "2024-06-13T23:51:29.956462",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.925259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#閾値の変更ができる。ただし今回は二値分類ですでに0/1が出ているため、意味がない\\n\\n# 予測\\ny_proba = stacking.predict(X_test)\\n\\n# 閾値の設定と調整\\nthreshold = 0.5  # デフォルトの閾値\\ny_pred = (y_proba >= threshold).astype(int)\\n\\n# 精度の計算\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Accuracy with threshold {threshold}: {accuracy:.4f}')\\n\\n# 閾値を変更して精度を再計算\\nthreshold = 0.8\\ny_pred_adjusted = (y_proba >= threshold).astype(int)\\naccuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\\nprint(f'Accuracy with threshold {threshold}: {accuracy_adjusted:.4f}')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#閾値の変更ができる。ただし今回は二値分類ですでに0/1が出ているため、意味がない\n",
    "\n",
    "# 予測\n",
    "y_proba = stacking.predict(X_test)\n",
    "\n",
    "# 閾値の設定と調整\n",
    "threshold = 0.5  # デフォルトの閾値\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# 精度の計算\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with threshold {threshold}: {accuracy:.4f}')\n",
    "\n",
    "# 閾値を変更して精度を再計算\n",
    "threshold = 0.8\n",
    "y_pred_adjusted = (y_proba >= threshold).astype(int)\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "print(f'Accuracy with threshold {threshold}: {accuracy_adjusted:.4f}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60b564af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:29.995730Z",
     "iopub.status.busy": "2024-06-13T23:51:29.994927Z",
     "iopub.status.idle": "2024-06-13T23:51:30.004186Z",
     "shell.execute_reply": "2024-06-13T23:51:30.002840Z"
    },
    "papermill": {
     "duration": 0.031716,
     "end_time": "2024-06-13T23:51:30.006761",
     "exception": false,
     "start_time": "2024-06-13T23:51:29.975045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#SMOTE（Synthetic Minority Over-sampling Technique）は、クラス不均衡を改善するためのデータ合成技術です。\\n#クラス不均衡とは、データセット内のクラスの分布が偏っている状態を指します。例えば、分類問題において、クラスAが90%を占め、クラスBが10%しかない場合、これはクラス不均衡なデータセットです。\\n#今回は二値分類で存在確率が50％ずつであるため、不要\\n\\nfrom imblearn.over_sampling import SMOTE\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# SMOTEの適用\\nsmote = SMOTE(random_state=42)\\nX_resampled, y_resampled = smote.fit_resample(X_train, y_train)\\n\\n# 元のデータのクラス分布\\nprint(\"Original dataset shape:\", Counter(X_train))\\n\\n# SMOTE適用後のデータのクラス分布\\nprint(\"Resampled dataset shape:\", Counter(X_resampled))\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#SMOTE（Synthetic Minority Over-sampling Technique）は、クラス不均衡を改善するためのデータ合成技術です。\n",
    "#クラス不均衡とは、データセット内のクラスの分布が偏っている状態を指します。例えば、分類問題において、クラスAが90%を占め、クラスBが10%しかない場合、これはクラス不均衡なデータセットです。\n",
    "#今回は二値分類で存在確率が50％ずつであるため、不要\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTEの適用\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 元のデータのクラス分布\n",
    "print(\"Original dataset shape:\", Counter(X_train))\n",
    "\n",
    "# SMOTE適用後のデータのクラス分布\n",
    "print(\"Resampled dataset shape:\", Counter(X_resampled))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06cba793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.045904Z",
     "iopub.status.busy": "2024-06-13T23:51:30.045445Z",
     "iopub.status.idle": "2024-06-13T23:51:30.054220Z",
     "shell.execute_reply": "2024-06-13T23:51:30.053008Z"
    },
    "papermill": {
     "duration": 0.032557,
     "end_time": "2024-06-13T23:51:30.057790",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.025233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# モデルの構築と学習\\nmodels = [\\n    KNeighborsClassifier(),\\n    LogisticRegression(max_iter=1000),\\n    SVC(),\\n    RandomForestClassifier(),\\n    XGBClassifier(),\\n    LGBMClassifier(verbose=-1),\\n    DecisionTreeClassifier(),\\n    GradientBoostingClassifier(),\\n    AdaBoostClassifier(),\\n    GaussianNB(),\\n    MLPClassifier(max_iter=1000)\\n]\\n\\n# 結果を保存するためのデータフレームを作成\\nresults = pd.DataFrame(columns=[\\'Model\\', \\'accuracy\\'])\\n\\n# 各モデルに対して学習と評価を行うループ\\nfor model in models:\\n    model_name = model.__class__.__name__  # モデルの名前を取得\\n    model.fit(X_train, y_train)  # モデルの学習\\n    y_pred = model.predict(X_test)  # 予測\\n    \\n    accuracy = accuracy_score(y_test, y_pred)  # 平均二乗誤差を計算\\n    \\n    # 結果をデータフレームに登録\\n    results = pd.concat([results, pd.DataFrame({\\'Model\\': [model_name], \\'accuracy\\': [accuracy]})], ignore_index=True)\\n\\n# MSEによって結果をソート\\nresults = results.sort_values(by=\\'accuracy\\')\\n\\n# 結果を出力\\ndisplay(results)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの構築と学習\n",
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier(verbose=-1),\n",
    "    DecisionTreeClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# 結果を保存するためのデータフレームを作成\n",
    "results = pd.DataFrame(columns=['Model', 'accuracy'])\n",
    "\n",
    "# 各モデルに対して学習と評価を行うループ\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__  # モデルの名前を取得\n",
    "    model.fit(X_train, y_train)  # モデルの学習\n",
    "    y_pred = model.predict(X_test)  # 予測\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 平均二乗誤差を計算\n",
    "    \n",
    "    # 結果をデータフレームに登録\n",
    "    results = pd.concat([results, pd.DataFrame({'Model': [model_name], 'accuracy': [accuracy]})], ignore_index=True)\n",
    "\n",
    "# MSEによって結果をソート\n",
    "results = results.sort_values(by='accuracy')\n",
    "\n",
    "# 結果を出力\n",
    "display(results)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf486f",
   "metadata": {
    "papermill": {
     "duration": 0.019033,
     "end_time": "2024-06-13T23:51:30.096219",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.077186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\taccuracy\n",
    "* 9\tGaussianNB\t0.733755\n",
    "* 6\tDecisionTreeClassifier\t0.748131\n",
    "* 0\tKNeighborsClassifier\t0.772858\n",
    "* 1\tLogisticRegression\t0.781484\n",
    "* 8\tAdaBoostClassifier\t0.786084\n",
    "* 10\tMLPClassifier\t0.787234\n",
    "* 4\tXGBClassifier\t0.788959\n",
    "* 2\tSVC\t0.791834\n",
    "* 3\tRandomForestClassifier\t0.792409\n",
    "* 7\tGradientBoostingClassifier\t0.792409\n",
    "* 5\tLGBMClassifier\t0.806210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597033dd",
   "metadata": {
    "papermill": {
     "duration": 0.018211,
     "end_time": "2024-06-13T23:51:30.134261",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.116050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ダメだったこと\n",
    "* 'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck'　が1以上の合計値をカウントする。また、左の5つの要素を削除する\n",
    "* TrueとFalseの割合がほとんど同じだった、\"HomePlanet_Mars\",\"Destination_PSO J318.5-22\"の要素を削除する\n",
    "* lastnameの数をカウントして、その量を特徴量とすること\n",
    "* lastnameとCabin別に数値をカウントして、その量を特徴量とすること　→　ただし、model accuracyはよかった\n",
    "* 歪度の調整。ShoppingMall,VRDeck,Spa,FoodCourt,VIP,RoomService,pay_sum,PassengerNum_yは横軸が伸びていたので調整\n",
    "* stackingでmeta_modelをLGBM、XGBM、RFC、GBC、ABCへ変更\n",
    "* stackingでcvを5から10へ変更\n",
    "* stackingでtestsizeを0.05や0.4などに変更\n",
    "* 外れ値を今以上に増やす。6から20ほどに増やした\n",
    "* 欠損値処理をVIPごとに分けて実施。VIPであれば、VIPの中央値を補完し、VIP出ない場合は0にした\n",
    "* 1人当たりの支払金額を特徴量として追加した\n",
    "* HomeとDestinationの特徴量を合わせて、発着地で新たな特徴量を作成。HomeとDestinationを削除した\n",
    "* VotingClassifierのsoftを利用し、アンサンブルを実施した\n",
    "* 全てのカテゴリ変数をラベルエンコーディングへ変更した。destinationやHomePlanet、cabinなど。\n",
    "* 外れ値の検出をもう一度行った。0.01の閾値でIsolation Forestによる外れ値検出をした\n",
    "* ageとpay_sumを掛け算した、age_payという新しい特徴量を作成\n",
    "* VIP,Destination,homeplanetの特徴量を削除\n",
    "* LightGBMでoptunaを利用\n",
    "* XGBでoptunaを利用。ただし、VIPなど関係ない特徴量も一部削除\n",
    "\n",
    "効果が出たこと\n",
    "* 'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck'を0/1のカテゴリーでなく、数値で表す\n",
    "* \"Cabin_2\"を0/1のカテゴリーでなく、数値で表す\n",
    "* 'RoomService', 'FoodCourt', 'ShoppingMall','Spa', 'VRDeck'を合計した、\"pay_sum\"の要素を追加する\n",
    "* Cabin_1をカテゴリーではなく、Trueの少ない順に1~8の数字を割り当てた（ただし、model accuracyではほぼ低下していたため、モデルにより使用可否を変えるべきかも）以下No2でこのmodel accuracyは表示\n",
    "* StandardScalerではなく、RobustScalerでスケーリングする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b65152",
   "metadata": {
    "papermill": {
     "duration": 0.018602,
     "end_time": "2024-06-13T23:51:30.171441",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.152839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# \tModel\taccuracy（No2）\n",
    "* 9\tGaussianNB\t0.714204\n",
    "* 6\tDecisionTreeClassifier\t0.755032\n",
    "* 0\tKNeighborsClassifier\t0.780909\n",
    "* 8\tAdaBoostClassifier\t0.784359\n",
    "* 1\tLogisticRegression\t0.784934\n",
    "* 3\tRandomForestClassifier\t0.787234\n",
    "* 10\tMLPClassifier\t0.790684\n",
    "* 2\tSVC\t0.792984\n",
    "* 7\tGradientBoostingClassifier\t0.794710\n",
    "* 4\tXGBClassifier\t0.799310\n",
    "* 5\tLGBMClassifier\t0.803910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5dda542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.211373Z",
     "iopub.status.busy": "2024-06-13T23:51:30.210923Z",
     "iopub.status.idle": "2024-06-13T23:51:30.220480Z",
     "shell.execute_reply": "2024-06-13T23:51:30.219274Z"
    },
    "papermill": {
     "duration": 0.033046,
     "end_time": "2024-06-13T23:51:30.223172",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.190126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nx_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n#define objective function for hyperparameter optimization using optuna\\ndef objective(trial):\\n\\n  #define hyperparameters to optimize for\\n  params = {\\n      \\'n_estimators\\': trial.suggest_int(\\'n_estimators\\', 50, 1000),\\n      \\'max_depth\\': trial.suggest_int(\\'max_depth\\', 3, 10),\\n      \\'learning_rate\\': trial.suggest_loguniform(\\'learning_rate\\', 0.005, 1),\\n      \\'subsample\\': trial.suggest_uniform(\\'subsample\\', 0.1, 1),\\n      \\'colsample_bytree\\': trial.suggest_uniform(\\'colsample_bytree\\', 0.5, 1),\\n      #\\'gamma\\': trial.suggest_uniform(\\'gamma\\', 0, 1),\\n      \\'alpha\\': trial.suggest_loguniform(\\'alpha\\', 2, 5),\\n      \\'lambda\\': trial.suggest_loguniform(\\'lambda\\', 2, 5),\\n      \\'min_child_weight\\': trial.suggest_int(\\'min_child_weight\\', 1, 300)\\n  }\\n\\n  #create XGBClassifier model with optimized hyperparameters\\n  model = XGBClassifier(**params, random_state=0)\\n    \\n  #evaluate model using cross-validation\\n  score = cross_val_score(model, X, y, cv=5).mean()\\n    \\n  return score\\n\\n#run hyperparameter optimization with optuna\\nstudy = optuna.create_study(direction=\\'maximize\\')\\nstudy.optimize(objective, n_trials=50)\\nstudy.best_params\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "x_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#define objective function for hyperparameter optimization using optuna\n",
    "def objective(trial):\n",
    "\n",
    "  #define hyperparameters to optimize for\n",
    "  params = {\n",
    "      'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "      'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "      'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 1),\n",
    "      'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "      'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "      #'gamma': trial.suggest_uniform('gamma', 0, 1),\n",
    "      'alpha': trial.suggest_loguniform('alpha', 2, 5),\n",
    "      'lambda': trial.suggest_loguniform('lambda', 2, 5),\n",
    "      'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n",
    "  }\n",
    "\n",
    "  #create XGBClassifier model with optimized hyperparameters\n",
    "  model = XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "  #evaluate model using cross-validation\n",
    "  score = cross_val_score(model, X, y, cv=5).mean()\n",
    "    \n",
    "  return score\n",
    "\n",
    "#run hyperparameter optimization with optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "study.best_params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f519fe",
   "metadata": {
    "papermill": {
     "duration": 0.018689,
     "end_time": "2024-06-13T23:51:30.261830",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.243141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "{'n_estimators': 947,\n",
    " 'max_depth': 3,\n",
    " 'learning_rate': 0.007935842382929551,\n",
    " 'subsample': 0.9957504494825978,\n",
    " 'colsample_bytree': 0.6136711694856477,\n",
    " 'alpha': 3.5472522691711807,\n",
    " 'lambda': 4.966323147332355,\n",
    " 'min_child_weight': 17}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aad2e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.302759Z",
     "iopub.status.busy": "2024-06-13T23:51:30.302305Z",
     "iopub.status.idle": "2024-06-13T23:51:30.311180Z",
     "shell.execute_reply": "2024-06-13T23:51:30.309909Z"
    },
    "papermill": {
     "duration": 0.03357,
     "end_time": "2024-06-13T23:51:30.314298",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.280728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nparams = {\\'n_estimators\\': 146,\\n \\'max_depth\\': 10,\\n \\'learning_rate\\': 0.020428429252807186,\\n \\'subsample\\': 0.4755826453445764,\\n \\'colsample_bytree\\': 0.6622240313353329,\\n \\'alpha\\': 2.7894408629032132,\\n \\'lambda\\': 2.0202816357266684,\\n \\'min_child_weight\\': 16}\\n\\nmodel = XGBClassifier(**params, random_state=0)\\nmodel.fit(X, y)\\n\\nsubmit = model.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "params = {'n_estimators': 146,\n",
    " 'max_depth': 10,\n",
    " 'learning_rate': 0.020428429252807186,\n",
    " 'subsample': 0.4755826453445764,\n",
    " 'colsample_bytree': 0.6622240313353329,\n",
    " 'alpha': 2.7894408629032132,\n",
    " 'lambda': 2.0202816357266684,\n",
    " 'min_child_weight': 16}\n",
    "\n",
    "model = XGBClassifier(**params, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "submit = model.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2a2308",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.355760Z",
     "iopub.status.busy": "2024-06-13T23:51:30.355319Z",
     "iopub.status.idle": "2024-06-13T23:51:30.367018Z",
     "shell.execute_reply": "2024-06-13T23:51:30.365784Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.035451,
     "end_time": "2024-06-13T23:51:30.369635",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.334184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#categorical featureなし / optunaあり\\n\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nx_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\ndef objective(trial):\\n\\n    params = {\\n        \\'objective\\': \\'binary\\',\\n        \\'metric\\': \\'binary_logloss\\',\\n        \\'boosting\\': \\'gbdt\\',\\n        \\'max_depth\\':trial.suggest_int(\\'max_depth\\', 1, 10),\\n        \\'min_data_in_leaf\\':trial.suggest_int(\\'min_data_in_leaf\\', 1, 80),\\n        \\'learning_rate\\':trial.suggest_loguniform(\\'learning_rate\\', 0.001, 0.1),\\n        \\'lambda_l1\\': trial.suggest_loguniform(\\'lambda_l1\\', 1e-8, 10.0),\\n        \\'lambda_l2\\': trial.suggest_loguniform(\\'lambda_l2\\', 1e-8, 10.0),\\n        \\'num_leaves\\': trial.suggest_int(\\'num_leaves\\', 2, 512),\\n        \\'feature_fraction\\': trial.suggest_uniform(\\'feature_fraction\\', 0.4, 1.0),\\n        \\'bagging_fraction\\': trial.suggest_uniform(\\'bagging_fraction\\', 0.4, 1.0),\\n        \\'bagging_freq\\': trial.suggest_int(\\'bagging_freq\\', 0, 10),\\n        \\'min_child_samples\\': trial.suggest_int(\\'min_child_samples\\', 5, 100),\\n        \\'verbosity\\': -1,\\n        \\'random_state\\': 0,\\n    }\\n\\n\\n    lgb_train = lgb.Dataset(x_train_lgb,y_train_lgb)\\n    lgb_valid = lgb.Dataset(x_valid_lgb,y_valid_lgb)\\n\\n    gbm=lgb.train(\\n        params,\\n        lgb_train,\\n        valid_sets=[lgb_train, lgb_valid],\\n        valid_names=[\\'train\\', \\'valid\\'],\\n        num_boost_round=1000,\\n        callbacks=[lgb.early_stopping(100),lgb.log_evaluation(period=100)])\\n    \\n    y_prob = gbm.predict(x_valid_lgb)\\n    y_pred = np.round(y_prob)\\n    return accuracy_score(y_valid_lgb, y_pred)\\n\\nstudy = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=42))\\nstudy.optimize(objective, n_trials=100)\\nstudy.best_params\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#categorical featureなし / optunaあり\n",
    "\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "x_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'max_depth':trial.suggest_int('max_depth', 1, 10),\n",
    "        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 1, 80),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'verbosity': -1,\n",
    "        'random_state': 0,\n",
    "    }\n",
    "\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train_lgb,y_train_lgb)\n",
    "    lgb_valid = lgb.Dataset(x_valid_lgb,y_valid_lgb)\n",
    "\n",
    "    gbm=lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        valid_names=['train', 'valid'],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100),lgb.log_evaluation(period=100)])\n",
    "    \n",
    "    y_prob = gbm.predict(x_valid_lgb)\n",
    "    y_pred = np.round(y_prob)\n",
    "    return accuracy_score(y_valid_lgb, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9447121",
   "metadata": {
    "papermill": {
     "duration": 0.018993,
     "end_time": "2024-06-13T23:51:30.407800",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.388807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "{'max_depth': 10,<br>\n",
    " 'min_data_in_leaf': 11,<br>\n",
    " 'learning_rate': 0.02200392301642105,<br>\n",
    " 'lambda_l1': 0.06094769921592947,<br>\n",
    " 'lambda_l2': 1.844632396279779e-05,<br>\n",
    " 'num_leaves': 228,<br>\n",
    " 'feature_fraction': 0.8520391737889896,<br>\n",
    " 'bagging_fraction': 0.9240371869522627,<br>\n",
    " 'bagging_freq': 4,<br>\n",
    " 'min_child_samples': 39}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5117d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.449075Z",
     "iopub.status.busy": "2024-06-13T23:51:30.448618Z",
     "iopub.status.idle": "2024-06-13T23:51:30.458002Z",
     "shell.execute_reply": "2024-06-13T23:51:30.456763Z"
    },
    "papermill": {
     "duration": 0.03354,
     "end_time": "2024-06-13T23:51:30.460629",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.427089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nx_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nparams = {\\n\\'objective\\': \\'binary\\',\\n\\'metric\\': \\'binary_logloss\\',\\n\\'boosting\\': \\'gbdt\\',\\n\\'max_depth\\': 10,\\n\\'min_data_in_leaf\\': 11,\\n\\'learning_rate\\': 0.02200392301642105,\\n\\'lambda_l1\\': 0.06094769921592947,\\n\\'lambda_l2\\': 1.844632396279779e-05,\\n\\'num_leaves\\': 228,\\n\\'feature_fraction\\': 0.8520391737889896,\\n\\'bagging_fraction\\': 0.9240371869522627,\\n\\'bagging_freq\\': 4,\\n\\'min_child_samples\\': 39,\\n\\'verbosity\\': -1,\\n\\'random_state\\': 0,\\n}\\n\\n\\nlgb_train = lgb.Dataset(x_train_lgb,y_train_lgb)\\nlgb_valid = lgb.Dataset(x_valid_lgb,y_valid_lgb)\\n\\ngbm=lgb.train(\\n    params,\\n    lgb_train,\\n    valid_sets=[lgb_train, lgb_valid],\\n    valid_names=[\\'train\\', \\'valid\\'],\\n    num_boost_round=1000,\\n    callbacks=[lgb.early_stopping(100),lgb.log_evaluation(period=100)])\\n\\nsubmit = gbm.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "x_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "'objective': 'binary',\n",
    "'metric': 'binary_logloss',\n",
    "'boosting': 'gbdt',\n",
    "'max_depth': 10,\n",
    "'min_data_in_leaf': 11,\n",
    "'learning_rate': 0.02200392301642105,\n",
    "'lambda_l1': 0.06094769921592947,\n",
    "'lambda_l2': 1.844632396279779e-05,\n",
    "'num_leaves': 228,\n",
    "'feature_fraction': 0.8520391737889896,\n",
    "'bagging_fraction': 0.9240371869522627,\n",
    "'bagging_freq': 4,\n",
    "'min_child_samples': 39,\n",
    "'verbosity': -1,\n",
    "'random_state': 0,\n",
    "}\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train_lgb,y_train_lgb)\n",
    "lgb_valid = lgb.Dataset(x_valid_lgb,y_valid_lgb)\n",
    "\n",
    "gbm=lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(100),lgb.log_evaluation(period=100)])\n",
    "\n",
    "submit = gbm.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa101101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.501033Z",
     "iopub.status.busy": "2024-06-13T23:51:30.500589Z",
     "iopub.status.idle": "2024-06-13T23:51:30.510013Z",
     "shell.execute_reply": "2024-06-13T23:51:30.508939Z"
    },
    "papermill": {
     "duration": 0.032765,
     "end_time": "2024-06-13T23:51:30.512608",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.479843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Stratified K-Foldの活用。TransportedのTrueとFalseが既存のデータと同じ存在割合になるように、train_test_splitを行う\\n\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# ベースモデルの定義\\nbase_models = [\\n    (\\'knn\\', KNeighborsClassifier()),\\n    (\\'lr\\', LogisticRegression(max_iter=1000)),\\n    (\\'svc\\', SVC(probability=True)),\\n    (\\'rf\\', RandomForestClassifier()),\\n    (\\'xgb\\', XGBClassifier()),\\n    (\\'lgbm\\', LGBMClassifier(verbose=-1))\\n]\\n\\n# メタモデルの定義\\nmeta_model = LogisticRegression()\\n\\n# Stacking Classifierの定義\\nstacking = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\\n\\n# Stratified K-Foldの定義\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\\n\\n# Stratified K-Foldクロスバリデーションの実行とモデルの学習\\nfor train_index, test_index in skf.split(X, y):\\n    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\\n    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\\n    \\n    # モデルの学習\\n    stacking.fit(X_train_fold, y_train_fold)\\n\\n    # モデルの評価\\n    score = stacking.score(X_test_fold, y_test_fold)\\n    print(f\\'Fold Accuracy: {score:.4f}\\')\\n\\n\\nsubmit = stacking.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Stratified K-Foldの活用。TransportedのTrueとFalseが既存のデータと同じ存在割合になるように、train_test_splitを行う\n",
    "\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ベースモデルの定義\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('lgbm', LGBMClassifier(verbose=-1))\n",
    "]\n",
    "\n",
    "# メタモデルの定義\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking Classifierの定義\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Stratified K-Foldの定義\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Stratified K-Foldクロスバリデーションの実行とモデルの学習\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # モデルの学習\n",
    "    stacking.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # モデルの評価\n",
    "    score = stacking.score(X_test_fold, y_test_fold)\n",
    "    print(f'Fold Accuracy: {score:.4f}')\n",
    "\n",
    "\n",
    "submit = stacking.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d10fd08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.553487Z",
     "iopub.status.busy": "2024-06-13T23:51:30.553056Z",
     "iopub.status.idle": "2024-06-13T23:51:30.562839Z",
     "shell.execute_reply": "2024-06-13T23:51:30.561672Z"
    },
    "papermill": {
     "duration": 0.033486,
     "end_time": "2024-06-13T23:51:30.565498",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.532012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Voting Classifier：複数の異なる機械学習モデルの予測結果を組み合わせて、最終的な予測結果を決定するためのアンサンブル学習手法の一つ\\n#Soft Voting (確率平均法)とは、各モデルが予測するクラスの確率を平均し、その平均確率が最も高いクラスを最終的な予測とします。この方法では、モデルが予測した各クラスの確率の情報を利用します。\\n\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# ベースモデルの定義\\nbase_models = [\\n    (\\'knn\\', KNeighborsClassifier()),\\n    (\\'lr\\', LogisticRegression(max_iter=1000)),\\n    (\\'svc\\', SVC(probability=True)),\\n    (\\'rf\\', RandomForestClassifier()),\\n    (\\'xgb\\', XGBClassifier()),\\n    (\\'lgb\\', LGBMClassifier(verbose=-1))\\n]\\n\\n# メタモデルの定義\\nmeta_model = LogisticRegression()\\n\\n# Soft Voting Classifierの定義\\nvoting_clf_soft = VotingClassifier(estimators=base_models, voting=\\'soft\\')\\n\\n# Stacking Classifierの学習\\nvoting_clf_soft.fit(X_train, y_train)\\n# 予測\\ny_pred = voting_clf_soft.predict(X_test)\\n# 精度の評価\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\'Soft Voting Accuracy: {accuracy:.4f}\\')\\n\\n\\nsubmit = voting_clf_soft.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Voting Classifier：複数の異なる機械学習モデルの予測結果を組み合わせて、最終的な予測結果を決定するためのアンサンブル学習手法の一つ\n",
    "#Soft Voting (確率平均法)とは、各モデルが予測するクラスの確率を平均し、その平均確率が最も高いクラスを最終的な予測とします。この方法では、モデルが予測した各クラスの確率の情報を利用します。\n",
    "\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ベースモデルの定義\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('lgb', LGBMClassifier(verbose=-1))\n",
    "]\n",
    "\n",
    "# メタモデルの定義\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Soft Voting Classifierの定義\n",
    "voting_clf_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
    "\n",
    "# Stacking Classifierの学習\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "# 予測\n",
    "y_pred = voting_clf_soft.predict(X_test)\n",
    "# 精度の評価\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Soft Voting Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "submit = voting_clf_soft.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e77a9452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.606917Z",
     "iopub.status.busy": "2024-06-13T23:51:30.606492Z",
     "iopub.status.idle": "2024-06-13T23:51:30.616281Z",
     "shell.execute_reply": "2024-06-13T23:51:30.615077Z"
    },
    "papermill": {
     "duration": 0.033718,
     "end_time": "2024-06-13T23:51:30.619045",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.585327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGradientBoostingClassifier\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nparameters = {\\n     \"n_estimators\":[i for i in range(10,100,10)],\\n     \"learning_rate\":[0.01],\\n     \"criterion\":[\"friedman_mse\"],\\n     \"max_depth\":[i for i in range(1,5,1)],\\n     \"min_samples_split\": [2,4,5,10,12,16],\\n     \"random_state\":[3]}\\n#交差検証+グリッドサーチにより最良パラメータの検索\\nclf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10)\\nclf.fit(X, y)\\n\\nprint(\"最良パラメータ: {}\".format(clf.best_params_))\\nprint(\"最良交差検証スコア: {:.2f}\".format(clf.best_score_))\\n# # 最良パラメータ: {\\'criterion\\': \\'friedman_mse\\', \\'learning_rate\\': 0.01, \\'max_depth\\': 4, \\'min_samples_split\\': 2, \\'random_state\\': 3}\\n# # 最良交差検証スコア: 0.83\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# モデルの構築と学習\\nmodel = GradientBoostingClassifier(criterion=\"friedman_mse\", max_depth=4, min_samples_split=2, n_estimators=90, learning_rate=0.01, random_state=3)\\n#最良パラメータ: {\\'criterion\\': \\'friedman_mse\\', \\'learning_rate\\': 0.01, \\'max_depth\\': 4, \\'min_samples_split\\': 2, \\'n_estimators\\': 90, \\'random_state\\': 3}\\n#最良交差検証スコア: 0.74\\n\\n# 各モデルに対して学習と評価を行うループ\\nmodel.fit(X_train, y_train)  # モデルの学習\\ny_pred = model.predict(X_test)  # 予測\\n\\naccuracy = accuracy_score(y_test, y_pred)  # 平均二乗誤差を計算\\nprint(accuracy)\\n\\nsubmit = model.predict(df_test)\\nprint(submit)\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "GradientBoostingClassifier\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "parameters = {\n",
    "     \"n_estimators\":[i for i in range(10,100,10)],\n",
    "     \"learning_rate\":[0.01],\n",
    "     \"criterion\":[\"friedman_mse\"],\n",
    "     \"max_depth\":[i for i in range(1,5,1)],\n",
    "     \"min_samples_split\": [2,4,5,10,12,16],\n",
    "     \"random_state\":[3]}\n",
    "#交差検証+グリッドサーチにより最良パラメータの検索\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"最良パラメータ: {}\".format(clf.best_params_))\n",
    "print(\"最良交差検証スコア: {:.2f}\".format(clf.best_score_))\n",
    "# # 最良パラメータ: {'criterion': 'friedman_mse', 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_split': 2, 'random_state': 3}\n",
    "# # 最良交差検証スコア: 0.83\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの構築と学習\n",
    "model = GradientBoostingClassifier(criterion=\"friedman_mse\", max_depth=4, min_samples_split=2, n_estimators=90, learning_rate=0.01, random_state=3)\n",
    "#最良パラメータ: {'criterion': 'friedman_mse', 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 90, 'random_state': 3}\n",
    "#最良交差検証スコア: 0.74\n",
    "\n",
    "# 各モデルに対して学習と評価を行うループ\n",
    "model.fit(X_train, y_train)  # モデルの学習\n",
    "y_pred = model.predict(X_test)  # 予測\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)  # 平均二乗誤差を計算\n",
    "print(accuracy)\n",
    "\n",
    "submit = model.predict(df_test)\n",
    "print(submit)\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6517c31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.660776Z",
     "iopub.status.busy": "2024-06-13T23:51:30.660340Z",
     "iopub.status.idle": "2024-06-13T23:51:30.668723Z",
     "shell.execute_reply": "2024-06-13T23:51:30.667554Z"
    },
    "papermill": {
     "duration": 0.032537,
     "end_time": "2024-06-13T23:51:30.671460",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.638923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\nlre = LogisticRegression()\\nparam_test = {\\'C\\':[0.001,0.01,0.1,1,10,100,1000]}\\n#Cとは、「コストパラメーター」の略であり、誤分類を許容する指標のこと。Cが大きいと誤分類を許容しない（外れ値をいれて評価）ため、学習されやすくなる。Cが小さすぎると誤分類を許容する（外れ値をいれずに評価）ため、学習が進みにくい。基本は1である\\n\\ngrid = GridSearchCV(estimator = lre, param_grid = param_test, scoring=\\'accuracy\\', cv=10)\\ngrid.fit(X, y)\\nprint(grid.best_params_, grid.best_score_, sep=\"\\n\")\\n\\n\\nsubmit = model.predict(df_test)\\nprint(submit)\\nsample_submission[\"Transported\"]=submit\\ndf_submit = sample_submission\\ndf_submit = df_submit.replace([0,1],[False,True])\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "lre = LogisticRegression()\n",
    "param_test = {'C':[0.001,0.01,0.1,1,10,100,1000]}\n",
    "#Cとは、「コストパラメーター」の略であり、誤分類を許容する指標のこと。Cが大きいと誤分類を許容しない（外れ値をいれて評価）ため、学習されやすくなる。Cが小さすぎると誤分類を許容する（外れ値をいれずに評価）ため、学習が進みにくい。基本は1である\n",
    "\n",
    "grid = GridSearchCV(estimator = lre, param_grid = param_test, scoring='accuracy', cv=10)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_, grid.best_score_, sep=\"\\n\")\n",
    "\n",
    "\n",
    "submit = model.predict(df_test)\n",
    "print(submit)\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d123419d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:30.713420Z",
     "iopub.status.busy": "2024-06-13T23:51:30.712984Z",
     "iopub.status.idle": "2024-06-13T23:51:32.453311Z",
     "shell.execute_reply": "2024-06-13T23:51:32.451836Z"
    },
    "papermill": {
     "duration": 1.764753,
     "end_time": "2024-06-13T23:51:32.456211",
     "exception": false,
     "start_time": "2024-06-13T23:51:30.691458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttrain's binary_logloss: 0.282784\tvalid's binary_logloss: 0.435194\n",
      "[200]\ttrain's binary_logloss: 0.230351\tvalid's binary_logloss: 0.456092\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttrain's binary_logloss: 0.339771\tvalid's binary_logloss: 0.428847\n",
      "0.7905035971223021\n",
      "[1. 0. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Lightgbm\n",
    "\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "X = X[selected_columns]\n",
    "y = df_train['Transported']\n",
    "\n",
    "x_train_lgb, x_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "params = {'objective': 'binary',\n",
    "          'metric': 'binary_logloss',\n",
    "          'boosting': 'gbdt',\n",
    "          'verbosity': -1,\n",
    "          'random_state': 1}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train_lgb,y_train_lgb)\n",
    "lgb_valid = lgb.Dataset(x_valid_lgb,y_valid_lgb)\n",
    "\n",
    "gbm=lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    num_boost_round=5000,\n",
    "    callbacks=[lgb.early_stopping(200),lgb.log_evaluation(period=100)])\n",
    "\n",
    "y_prob = gbm.predict(x_valid_lgb)\n",
    "y_pred = np.round(y_prob)\n",
    "print(accuracy_score(y_valid_lgb, y_pred))\n",
    "\n",
    "df_test = df_test[selected_columns]\n",
    "submit = gbm.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"]=submit\n",
    "df_submit = sample_submission\n",
    "df_submit = df_submit.replace([0,1],[False,True])\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "612910c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:32.499377Z",
     "iopub.status.busy": "2024-06-13T23:51:32.498919Z",
     "iopub.status.idle": "2024-06-13T23:51:32.515493Z",
     "shell.execute_reply": "2024-06-13T23:51:32.513978Z"
    },
    "papermill": {
     "duration": 0.041317,
     "end_time": "2024-06-13T23:51:32.518189",
     "exception": false,
     "start_time": "2024-06-13T23:51:32.476872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#ハイパーパラメータの調整を行ったstacking\\n\\ndf_submit = pd.DataFrame()\\ndf_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\\n\\n# 説明変数と目的変数を選択\\nX = df_train.drop(\"Transported\", axis=1)\\ny = df_train[\\'Transported\\']\\n\\n# データの分割\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nparam_grid_knn = {\\n    \\'n_neighbors\\': [3, 5, 7],\\n    \\'weights\\': [\\'uniform\\', \\'distance\\'],\\n    \\'metric\\': [\\'euclidean\\', \\'manhattan\\']\\n}\\n\\nparam_grid_lr = {\\n    \\'C\\': [0.1, 1, 10, 100],\\n    \\'solver\\': [\\'newton-cg\\', \\'lbfgs\\', \\'liblinear\\']\\n}\\n\\nparam_grid_svc = {\\n    \\'C\\': [0.1, 1, 10, 100],\\n    \\'gamma\\': [1, 0.1, 0.01, 0.001],\\n    \\'kernel\\': [\\'rbf\\', \\'linear\\']\\n}\\n\\nparam_grid_rf = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [None, 10, 20, 30],\\n    \\'min_samples_split\\': [2, 5, 10]\\n}\\n\\nparam_grid_xgb = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'learning_rate\\': [0.01, 0.1, 0.2],\\n    \\'max_depth\\': [3, 6, 9]\\n}\\n\\nparam_grid_lgbm = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'learning_rate\\': [0.01, 0.1, 0.2],\\n    \\'num_leaves\\': [31, 62, 127]\\n}\\n\\nknn = KNeighborsClassifier()\\nlr = LogisticRegression(max_iter=1000)\\nsvc = SVC(probability=True)\\nrf = RandomForestClassifier()\\nxgb = XGBClassifier()\\nlgbm = LGBMClassifier()\\n\\n\\n#ハイパーパラメータをgridsearchで調整。これを入れると長くなるため、パラメーターだけ抽出して以下へ記載\\n\\nmodels_param_grid = [\\n    (knn, param_grid_knn),\\n    (lr, param_grid_lr),\\n    (rf, param_grid_rf),\\n    (xgb, param_grid_xgb),\\n    (lgbm, param_grid_lgbm)\\n]\\n\\n# Perform GridSearchCV for each model\\nbest_estimators = []\\nfor model, param_grid in models_param_grid:\\n    print(model)\\n    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\\'accuracy\\')\\n    grid_search.fit(X_train, y_train)\\n    best_estimators.append((model.__class__.__name__, grid_search.best_estimator_))\\n\\n# Output the best estimators\\nfor name, estimator in best_estimators:\\n    print(f\\'Best estimator for {name}: {estimator}\\')\\n\\n#ハイパーパラメータの一覧\\nKNeighborsClassifier()\\nLogisticRegression(max_iter=1000)\\nRandomForestClassifier()\\nXGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=None, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              multi_strategy=None, n_estimators=None, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, ...)\\nLGBMClassifier(verbose=-1)\\nBest estimator for KNeighborsClassifier: KNeighborsClassifier(metric=\\'manhattan\\', n_neighbors=7)\\nBest estimator for LogisticRegression: LogisticRegression(C=1, max_iter=1000, solver=\\'liblinear\\')\\nBest estimator for RandomForestClassifier: RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=200)\\nBest estimator for XGBClassifier: XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=0.2, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=3, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              multi_strategy=None, n_estimators=200, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, ...)\\nBest estimator for LGBMClassifier: LGBMClassifier(verbose=-1)    \\n    \\nbase_models = [\\n    (\\'knn\\', KNeighborsClassifier(metric=\\'manhattan\\', n_neighbors=7)),\\n    (\\'lr\\', LogisticRegression(C=1, max_iter=1000, solver=\\'liblinear\\')),\\n    (\\'svc\\', SVC(probability=True)),\\n    (\\'rf\\', RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=200)),\\n    (\\'xgb\\', XGBClassifier(learning_rate=0.2,max_depth=3,n_estimators=200)),\\n    (\\'lgbm\\', LGBMClassifier(verbose=-1))\\n]\\n\\nmeta_model = LogisticRegression()\\n\\nstacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\\n\\n# Train the stacking classifier\\nstacking_clf.fit(X_train, y_train)\\n\\n# Predict and evaluate\\ny_pred = stacking_clf.predict(X_test)\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\'Stacking Model Accuracy: {accuracy:.4f}\\')\\n\\n# Predict on test data\\nsubmit = stacking_clf.predict(df_test)\\nsubmit = np.round(submit)\\nprint(submit)\\n\\nsample_submission[\"Transported\"] = submit\\nsample_submission = sample_submission.replace([0, 1], [False, True])\\nsample_submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\\n    \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#ハイパーパラメータの調整を行ったstacking\n",
    "\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit.to_csv(\"/kaggle/working/submission.csv\",index=False)\n",
    "\n",
    "# 説明変数と目的変数を選択\n",
    "X = df_train.drop(\"Transported\", axis=1)\n",
    "y = df_train['Transported']\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 9]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 62, 127]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "svc = SVC(probability=True)\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "\n",
    "#ハイパーパラメータをgridsearchで調整。これを入れると長くなるため、パラメーターだけ抽出して以下へ記載\n",
    "\n",
    "models_param_grid = [\n",
    "    (knn, param_grid_knn),\n",
    "    (lr, param_grid_lr),\n",
    "    (rf, param_grid_rf),\n",
    "    (xgb, param_grid_xgb),\n",
    "    (lgbm, param_grid_lgbm)\n",
    "]\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "best_estimators = []\n",
    "for model, param_grid in models_param_grid:\n",
    "    print(model)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimators.append((model.__class__.__name__, grid_search.best_estimator_))\n",
    "\n",
    "# Output the best estimators\n",
    "for name, estimator in best_estimators:\n",
    "    print(f'Best estimator for {name}: {estimator}')\n",
    "\n",
    "#ハイパーパラメータの一覧\n",
    "KNeighborsClassifier()\n",
    "LogisticRegression(max_iter=1000)\n",
    "RandomForestClassifier()\n",
    "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
    "              num_parallel_tree=None, random_state=None, ...)\n",
    "LGBMClassifier(verbose=-1)\n",
    "Best estimator for KNeighborsClassifier: KNeighborsClassifier(metric='manhattan', n_neighbors=7)\n",
    "Best estimator for LogisticRegression: LogisticRegression(C=1, max_iter=1000, solver='liblinear')\n",
    "Best estimator for RandomForestClassifier: RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=200)\n",
    "Best estimator for XGBClassifier: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
    "              num_parallel_tree=None, random_state=None, ...)\n",
    "Best estimator for LGBMClassifier: LGBMClassifier(verbose=-1)    \n",
    "    \n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(metric='manhattan', n_neighbors=7)),\n",
    "    ('lr', LogisticRegression(C=1, max_iter=1000, solver='liblinear')),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=200)),\n",
    "    ('xgb', XGBClassifier(learning_rate=0.2,max_depth=3,n_estimators=200)),\n",
    "    ('lgbm', LGBMClassifier(verbose=-1))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Stacking Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predict on test data\n",
    "submit = stacking_clf.predict(df_test)\n",
    "submit = np.round(submit)\n",
    "print(submit)\n",
    "\n",
    "sample_submission[\"Transported\"] = submit\n",
    "sample_submission = sample_submission.replace([0, 1], [False, True])\n",
    "sample_submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fde7d3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T23:51:32.561451Z",
     "iopub.status.busy": "2024-06-13T23:51:32.560965Z",
     "iopub.status.idle": "2024-06-13T23:51:32.571257Z",
     "shell.execute_reply": "2024-06-13T23:51:32.569970Z"
    },
    "papermill": {
     "duration": 0.035494,
     "end_time": "2024-06-13T23:51:32.574262",
     "exception": false,
     "start_time": "2024-06-13T23:51:32.538768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport shap\\n\\n# SHAP値の計算\\nexplainer = shap.TreeExplainer(gbm)\\nshap_values = explainer.shap_values(X_train)\\n\\n# SHAP値のプロット\\nshap.summary_plot(shap_values, X_train)\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import shap\n",
    "\n",
    "# SHAP値の計算\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# SHAP値のプロット\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.034205,
   "end_time": "2024-06-13T23:51:33.420019",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-13T23:51:19.385814",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
